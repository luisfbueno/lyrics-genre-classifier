{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fazendo a leitura de todos os Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bossa = pd.read_csv('dataset/bossa_nova.csv')\n",
    "funk = pd.read_csv('dataset/funk.csv')\n",
    "gospel = pd.read_csv('dataset/gospel.csv')\n",
    "sertanejo = pd.read_csv('dataset/sertanejo.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para que o algoritmo possa identificar qual o tipo de letra, é preciso adicionar uma coluna 'label' que contenha para cada tipo de música um valor. Depois disso, pode-se unir os quatro conjuntos de dados em um só."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bossa['label'] = 0\n",
    "funk['label'] = 1\n",
    "gospel['label'] = 2\n",
    "sertanejo['label'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [bossa,funk,gospel,sertanejo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = pd.concat(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# É preciso usar reset_index para que os indexes sejam ajustados ao novo conjunto\n",
    "lyrics.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyric</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nEu sei que vou te amar\\nPor toda a minha vi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nOlha que coisa mais linda\\nMais cheia de gr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nEra uma casa\\nMuito engraçada\\nNão tinha te...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nDe tudo, ao meu amor serei atento antes\\nE ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nQuando a luz dos olhos meus\\nE a luz dos ol...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               lyric  label\n",
       "0   \\nEu sei que vou te amar\\nPor toda a minha vi...      0\n",
       "1   \\nOlha que coisa mais linda\\nMais cheia de gr...      0\n",
       "2   \\nEra uma casa\\nMuito engraçada\\nNão tinha te...      0\n",
       "3   \\nDe tudo, ao meu amor serei atento antes\\nE ...      0\n",
       "4   \\nQuando a luz dos olhos meus\\nE a luz dos ol...      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, é preciso fazer um processamento de texto nas letras das músicas para que somente palavras relevantes sejam usadas pelo algoritmo. Para isso, é preciso substituir as quebras de linha ('\\n') por espaços, e remover símbolos de pontuação e stop words.\n",
    "\n",
    "Convém então criar um método que execute todos esses passos e depois seja aplicado em todo o conjunto de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obtendo o conjunto de stopwords, através da biblioteca nltk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['de',\n",
       " 'a',\n",
       " 'o',\n",
       " 'que',\n",
       " 'e',\n",
       " 'do',\n",
       " 'da',\n",
       " 'em',\n",
       " 'um',\n",
       " 'para',\n",
       " 'com',\n",
       " 'não',\n",
       " 'uma',\n",
       " 'os',\n",
       " 'no',\n",
       " 'se',\n",
       " 'na',\n",
       " 'por',\n",
       " 'mais',\n",
       " 'as',\n",
       " 'dos',\n",
       " 'como',\n",
       " 'mas',\n",
       " 'ao',\n",
       " 'ele',\n",
       " 'das',\n",
       " 'à',\n",
       " 'seu',\n",
       " 'sua',\n",
       " 'ou',\n",
       " 'quando',\n",
       " 'muito',\n",
       " 'nos',\n",
       " 'já',\n",
       " 'eu',\n",
       " 'também',\n",
       " 'só',\n",
       " 'pelo',\n",
       " 'pela',\n",
       " 'até',\n",
       " 'isso',\n",
       " 'ela',\n",
       " 'entre',\n",
       " 'depois',\n",
       " 'sem',\n",
       " 'mesmo',\n",
       " 'aos',\n",
       " 'seus',\n",
       " 'quem',\n",
       " 'nas',\n",
       " 'me',\n",
       " 'esse',\n",
       " 'eles',\n",
       " 'você',\n",
       " 'essa',\n",
       " 'num',\n",
       " 'nem',\n",
       " 'suas',\n",
       " 'meu',\n",
       " 'às',\n",
       " 'minha',\n",
       " 'numa',\n",
       " 'pelos',\n",
       " 'elas',\n",
       " 'qual',\n",
       " 'nós',\n",
       " 'lhe',\n",
       " 'deles',\n",
       " 'essas',\n",
       " 'esses',\n",
       " 'pelas',\n",
       " 'este',\n",
       " 'dele',\n",
       " 'tu',\n",
       " 'te',\n",
       " 'vocês',\n",
       " 'vos',\n",
       " 'lhes',\n",
       " 'meus',\n",
       " 'minhas',\n",
       " 'teu',\n",
       " 'tua',\n",
       " 'teus',\n",
       " 'tuas',\n",
       " 'nosso',\n",
       " 'nossa',\n",
       " 'nossos',\n",
       " 'nossas',\n",
       " 'dela',\n",
       " 'delas',\n",
       " 'esta',\n",
       " 'estes',\n",
       " 'estas',\n",
       " 'aquele',\n",
       " 'aquela',\n",
       " 'aqueles',\n",
       " 'aquelas',\n",
       " 'isto',\n",
       " 'aquilo',\n",
       " 'estou',\n",
       " 'está',\n",
       " 'estamos',\n",
       " 'estão',\n",
       " 'estive',\n",
       " 'esteve',\n",
       " 'estivemos',\n",
       " 'estiveram',\n",
       " 'estava',\n",
       " 'estávamos',\n",
       " 'estavam',\n",
       " 'estivera',\n",
       " 'estivéramos',\n",
       " 'esteja',\n",
       " 'estejamos',\n",
       " 'estejam',\n",
       " 'estivesse',\n",
       " 'estivéssemos',\n",
       " 'estivessem',\n",
       " 'estiver',\n",
       " 'estivermos',\n",
       " 'estiverem',\n",
       " 'hei',\n",
       " 'há',\n",
       " 'havemos',\n",
       " 'hão',\n",
       " 'houve',\n",
       " 'houvemos',\n",
       " 'houveram',\n",
       " 'houvera',\n",
       " 'houvéramos',\n",
       " 'haja',\n",
       " 'hajamos',\n",
       " 'hajam',\n",
       " 'houvesse',\n",
       " 'houvéssemos',\n",
       " 'houvessem',\n",
       " 'houver',\n",
       " 'houvermos',\n",
       " 'houverem',\n",
       " 'houverei',\n",
       " 'houverá',\n",
       " 'houveremos',\n",
       " 'houverão',\n",
       " 'houveria',\n",
       " 'houveríamos',\n",
       " 'houveriam',\n",
       " 'sou',\n",
       " 'somos',\n",
       " 'são',\n",
       " 'era',\n",
       " 'éramos',\n",
       " 'eram',\n",
       " 'fui',\n",
       " 'foi',\n",
       " 'fomos',\n",
       " 'foram',\n",
       " 'fora',\n",
       " 'fôramos',\n",
       " 'seja',\n",
       " 'sejamos',\n",
       " 'sejam',\n",
       " 'fosse',\n",
       " 'fôssemos',\n",
       " 'fossem',\n",
       " 'for',\n",
       " 'formos',\n",
       " 'forem',\n",
       " 'serei',\n",
       " 'será',\n",
       " 'seremos',\n",
       " 'serão',\n",
       " 'seria',\n",
       " 'seríamos',\n",
       " 'seriam',\n",
       " 'tenho',\n",
       " 'tem',\n",
       " 'temos',\n",
       " 'tém',\n",
       " 'tinha',\n",
       " 'tínhamos',\n",
       " 'tinham',\n",
       " 'tive',\n",
       " 'teve',\n",
       " 'tivemos',\n",
       " 'tiveram',\n",
       " 'tivera',\n",
       " 'tivéramos',\n",
       " 'tenha',\n",
       " 'tenhamos',\n",
       " 'tenham',\n",
       " 'tivesse',\n",
       " 'tivéssemos',\n",
       " 'tivessem',\n",
       " 'tiver',\n",
       " 'tivermos',\n",
       " 'tiverem',\n",
       " 'terei',\n",
       " 'terá',\n",
       " 'teremos',\n",
       " 'terão',\n",
       " 'teria',\n",
       " 'teríamos',\n",
       " 'teriam']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# É preciso baixar o conjunto de stopwords através do nltk.download_shell() -> d -> stopwords\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obtendo conjunto de símbolos de pontuação, através da biblioteca de string do Python**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Criando a função de processamento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processamento_texto(txt):\n",
    "    # remover quebras de linha\n",
    "    txt = txt.replace('\\n',' ')\n",
    "    # remover símbolos de pontuação, resultando em um array de caracteres\n",
    "    txt = [char for char in txt if char not in string.punctuation]\n",
    "    # depois, juntar os caracteres em palavras novamente e separá-los em uma lista de tokens\n",
    "    txt = ''.join(txt).split()\n",
    "    # por fim, remover as stopwords da lista\n",
    "    txt = [word for word in txt if word.lower() not in stopwords.words('portuguese')]\n",
    "    \n",
    "    return txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação do Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para fazer a predição, é preciso seguir alguns passos:\n",
    "\n",
    "1. Converter o texto das letras em uma lista de tokens únicos. Para isso, utiliza-se o Count Vectorizer do scikit, passando como analisador a função processamento_texto criada acima, para que as palavas sejam separadas de acordo com ela.\n",
    "2. Obter os valores Tf-idf de todas as palavras. Este valor indica a importância de cada palavra em relação a todo o conjunto de palavras das letras de música. Para isso, utiliza-se o TfidfTransformer, que gerará os valores com base no que foi obtido no passo anterior.\n",
    "3. Aplicar o modelo estatístico com base nos valores Tf-idf.\n",
    "\n",
    "Para facilitar a execução destes passos, será utilizado a estrutura de Pipeline presente no scikit, que permite que uma série de transformações sejam passadas, de forma que elas são executadas em ordem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separando o conjunto de dados em conjunto de treino e de teste**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "lyric_train,lyric_test,label_train,label_test = train_test_split(lyrics['lyric'],lyrics['label'],test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utilizando Naive-Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=processamento_texto)),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('nb',MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('bow', CountVectorizer(analyzer=<function processamento_texto at 0x7fe839f7f730>,\n",
       "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "        max_features=None, min_df=1, ngram_range=(1, 1), preproce...linear_tf=False, use_idf=True)), ('nb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(lyric_train,label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(lyric_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.61      0.73       219\n",
      "          1       0.95      0.75      0.84       253\n",
      "          2       0.85      0.94      0.90       236\n",
      "          3       0.63      0.90      0.74       252\n",
      "\n",
      "avg / total       0.84      0.80      0.80       960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(label_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utilizando Support Vector Machines**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "pipelineSVC = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=processamento_texto)),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('svc',SVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('bow', CountVectorizer(analyzer=<function processamento_texto at 0x7fe839f7f730>,\n",
       "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "        max_features=None, min_df=1, ngram_range=(1, 1), preproce...,\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelineSVC.fit(lyric_train,label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipelineSVC.predict(lyric_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.23      1.00      0.37       219\n",
      "          1       0.00      0.00      0.00       253\n",
      "          2       0.00      0.00      0.00       236\n",
      "          3       0.00      0.00      0.00       252\n",
      "\n",
      "avg / total       0.05      0.23      0.08       960\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luis/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(label_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'svc__C':[0.1,1,10,1000],'svc__gamma':[1,0.1,0.01,0.001,0.0001]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipelineSVC,param_grid,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV] svc__C=0.1, svc__gamma=1 ........................................\n",
      "[CV]  svc__C=0.1, svc__gamma=1, score=0.25935828877005346, total= 1.0min\n",
      "[CV] svc__C=0.1, svc__gamma=1 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svc__C=0.1, svc__gamma=1, score=0.26104417670682734, total= 1.1min\n",
      "[CV] svc__C=0.1, svc__gamma=1 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  3.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svc__C=0.1, svc__gamma=1, score=0.25906040268456376, total= 1.0min\n",
      "[CV] svc__C=0.1, svc__gamma=0.1 ......................................\n",
      "[CV]  svc__C=0.1, svc__gamma=0.1, score=0.25935828877005346, total= 1.1min\n",
      "[CV] svc__C=0.1, svc__gamma=0.1 ......................................\n",
      "[CV]  svc__C=0.1, svc__gamma=0.1, score=0.2597054886211513, total= 1.1min\n",
      "[CV] svc__C=0.1, svc__gamma=0.1 ......................................\n",
      "[CV]  svc__C=0.1, svc__gamma=0.1, score=0.25906040268456376, total= 1.0min\n",
      "[CV] svc__C=0.1, svc__gamma=0.01 .....................................\n",
      "[CV]  svc__C=0.1, svc__gamma=0.01, score=0.25935828877005346, total= 1.0min\n",
      "[CV] svc__C=0.1, svc__gamma=0.01 .....................................\n",
      "[CV]  svc__C=0.1, svc__gamma=0.01, score=0.2597054886211513, total= 1.0min\n",
      "[CV] svc__C=0.1, svc__gamma=0.01 .....................................\n",
      "[CV]  svc__C=0.1, svc__gamma=0.01, score=0.25906040268456376, total= 1.0min\n",
      "[CV] svc__C=0.1, svc__gamma=0.001 ....................................\n",
      "[CV]  svc__C=0.1, svc__gamma=0.001, score=0.25935828877005346, total= 1.0min\n",
      "[CV] svc__C=0.1, svc__gamma=0.001 ....................................\n",
      "[CV]  svc__C=0.1, svc__gamma=0.001, score=0.2597054886211513, total= 1.1min\n",
      "[CV] svc__C=0.1, svc__gamma=0.001 ....................................\n",
      "[CV]  svc__C=0.1, svc__gamma=0.001, score=0.25906040268456376, total= 1.0min\n",
      "[CV] svc__C=0.1, svc__gamma=0.0001 ...................................\n",
      "[CV]  svc__C=0.1, svc__gamma=0.0001, score=0.25935828877005346, total= 1.0min\n",
      "[CV] svc__C=0.1, svc__gamma=0.0001 ...................................\n",
      "[CV]  svc__C=0.1, svc__gamma=0.0001, score=0.2597054886211513, total= 1.0min\n",
      "[CV] svc__C=0.1, svc__gamma=0.0001 ...................................\n",
      "[CV]  svc__C=0.1, svc__gamma=0.0001, score=0.25906040268456376, total= 1.0min\n",
      "[CV] svc__C=1, svc__gamma=1 ..........................................\n",
      "[CV] . svc__C=1, svc__gamma=1, score=0.8262032085561497, total= 1.0min\n",
      "[CV] svc__C=1, svc__gamma=1 ..........................................\n",
      "[CV] . svc__C=1, svc__gamma=1, score=0.8112449799196787, total= 1.0min\n",
      "[CV] svc__C=1, svc__gamma=1 ..........................................\n",
      "[CV] . svc__C=1, svc__gamma=1, score=0.8214765100671141, total= 1.0min\n",
      "[CV] svc__C=1, svc__gamma=0.1 ........................................\n",
      "[CV]  svc__C=1, svc__gamma=0.1, score=0.7526737967914439, total= 1.0min\n",
      "[CV] svc__C=1, svc__gamma=0.1 ........................................\n",
      "[CV]  svc__C=1, svc__gamma=0.1, score=0.7563587684069611, total= 1.0min\n",
      "[CV] svc__C=1, svc__gamma=0.1 ........................................\n",
      "[CV]  svc__C=1, svc__gamma=0.1, score=0.7865771812080536, total= 1.0min\n",
      "[CV] svc__C=1, svc__gamma=0.01 .......................................\n",
      "[CV]  svc__C=1, svc__gamma=0.01, score=0.25935828877005346, total= 1.0min\n",
      "[CV] svc__C=1, svc__gamma=0.01 .......................................\n",
      "[CV]  svc__C=1, svc__gamma=0.01, score=0.2597054886211513, total= 1.0min\n",
      "[CV] svc__C=1, svc__gamma=0.01 .......................................\n",
      "[CV]  svc__C=1, svc__gamma=0.01, score=0.25906040268456376, total= 1.0min\n",
      "[CV] svc__C=1, svc__gamma=0.001 ......................................\n",
      "[CV]  svc__C=1, svc__gamma=0.001, score=0.25935828877005346, total= 1.0min\n",
      "[CV] svc__C=1, svc__gamma=0.001 ......................................\n",
      "[CV]  svc__C=1, svc__gamma=0.001, score=0.2597054886211513, total= 1.0min\n",
      "[CV] svc__C=1, svc__gamma=0.001 ......................................\n",
      "[CV]  svc__C=1, svc__gamma=0.001, score=0.25906040268456376, total= 1.0min\n",
      "[CV] svc__C=1, svc__gamma=0.0001 .....................................\n",
      "[CV]  svc__C=1, svc__gamma=0.0001, score=0.25935828877005346, total= 1.0min\n",
      "[CV] svc__C=1, svc__gamma=0.0001 .....................................\n",
      "[CV]  svc__C=1, svc__gamma=0.0001, score=0.2597054886211513, total= 1.2min\n",
      "[CV] svc__C=1, svc__gamma=0.0001 .....................................\n",
      "[CV]  svc__C=1, svc__gamma=0.0001, score=0.25906040268456376, total= 1.0min\n",
      "[CV] svc__C=10, svc__gamma=1 .........................................\n",
      "[CV]  svc__C=10, svc__gamma=1, score=0.8302139037433155, total= 1.0min\n",
      "[CV] svc__C=10, svc__gamma=1 .........................................\n",
      "[CV] . svc__C=10, svc__gamma=1, score=0.820615796519411, total= 1.0min\n",
      "[CV] svc__C=10, svc__gamma=1 .........................................\n",
      "[CV] . svc__C=10, svc__gamma=1, score=0.825503355704698, total= 1.0min\n",
      "[CV] svc__C=10, svc__gamma=0.1 .......................................\n",
      "[CV]  svc__C=10, svc__gamma=0.1, score=0.8275401069518716, total= 1.0min\n",
      "[CV] svc__C=10, svc__gamma=0.1 .......................................\n",
      "[CV]  svc__C=10, svc__gamma=0.1, score=0.8139223560910308, total= 1.0min\n",
      "[CV] svc__C=10, svc__gamma=0.1 .......................................\n",
      "[CV]  svc__C=10, svc__gamma=0.1, score=0.8174496644295302, total= 1.0min\n",
      "[CV] svc__C=10, svc__gamma=0.01 ......................................\n",
      "[CV]  svc__C=10, svc__gamma=0.01, score=0.7713903743315508, total= 1.0min\n",
      "[CV] svc__C=10, svc__gamma=0.01 ......................................\n",
      "[CV]  svc__C=10, svc__gamma=0.01, score=0.7724230254350736, total= 1.0min\n",
      "[CV] svc__C=10, svc__gamma=0.01 ......................................\n",
      "[CV]  svc__C=10, svc__gamma=0.01, score=0.7879194630872484, total= 1.0min\n",
      "[CV] svc__C=10, svc__gamma=0.001 .....................................\n",
      "[CV]  svc__C=10, svc__gamma=0.001, score=0.25935828877005346, total= 1.0min\n",
      "[CV] svc__C=10, svc__gamma=0.001 .....................................\n",
      "[CV]  svc__C=10, svc__gamma=0.001, score=0.2597054886211513, total= 1.0min\n",
      "[CV] svc__C=10, svc__gamma=0.001 .....................................\n",
      "[CV]  svc__C=10, svc__gamma=0.001, score=0.25906040268456376, total= 1.0min\n",
      "[CV] svc__C=10, svc__gamma=0.0001 ....................................\n",
      "[CV]  svc__C=10, svc__gamma=0.0001, score=0.25935828877005346, total= 1.0min\n",
      "[CV] svc__C=10, svc__gamma=0.0001 ....................................\n",
      "[CV]  svc__C=10, svc__gamma=0.0001, score=0.2597054886211513, total= 1.0min\n",
      "[CV] svc__C=10, svc__gamma=0.0001 ....................................\n",
      "[CV]  svc__C=10, svc__gamma=0.0001, score=0.25906040268456376, total= 1.0min\n",
      "[CV] svc__C=1000, svc__gamma=1 .......................................\n",
      "[CV]  svc__C=1000, svc__gamma=1, score=0.8302139037433155, total= 1.0min\n",
      "[CV] svc__C=1000, svc__gamma=1 .......................................\n",
      "[CV]  svc__C=1000, svc__gamma=1, score=0.821954484605087, total= 1.0min\n",
      "[CV] svc__C=1000, svc__gamma=1 .......................................\n",
      "[CV]  svc__C=1000, svc__gamma=1, score=0.825503355704698, total= 1.0min\n",
      "[CV] svc__C=1000, svc__gamma=0.1 .....................................\n",
      "[CV]  svc__C=1000, svc__gamma=0.1, score=0.8221925133689839, total= 1.2min\n",
      "[CV] svc__C=1000, svc__gamma=0.1 .....................................\n",
      "[CV]  svc__C=1000, svc__gamma=0.1, score=0.8139223560910308, total= 1.0min\n",
      "[CV] svc__C=1000, svc__gamma=0.1 .....................................\n",
      "[CV]  svc__C=1000, svc__gamma=0.1, score=0.8147651006711409, total= 1.0min\n",
      "[CV] svc__C=1000, svc__gamma=0.01 ....................................\n",
      "[CV]  svc__C=1000, svc__gamma=0.01, score=0.8248663101604278, total= 1.0min\n",
      "[CV] svc__C=1000, svc__gamma=0.01 ....................................\n",
      "[CV]  svc__C=1000, svc__gamma=0.01, score=0.8112449799196787, total= 1.2min\n",
      "[CV] svc__C=1000, svc__gamma=0.01 ....................................\n",
      "[CV]  svc__C=1000, svc__gamma=0.01, score=0.8120805369127517, total= 1.2min\n",
      "[CV] svc__C=1000, svc__gamma=0.001 ...................................\n",
      "[CV]  svc__C=1000, svc__gamma=0.001, score=0.8248663101604278, total= 1.0min\n",
      "[CV] svc__C=1000, svc__gamma=0.001 ...................................\n",
      "[CV]  svc__C=1000, svc__gamma=0.001, score=0.8139223560910308, total= 1.0min\n",
      "[CV] svc__C=1000, svc__gamma=0.001 ...................................\n",
      "[CV]  svc__C=1000, svc__gamma=0.001, score=0.8201342281879195, total= 1.0min\n",
      "[CV] svc__C=1000, svc__gamma=0.0001 ..................................\n",
      "[CV]  svc__C=1000, svc__gamma=0.0001, score=0.7740641711229946, total= 1.0min\n",
      "[CV] svc__C=1000, svc__gamma=0.0001 ..................................\n",
      "[CV]  svc__C=1000, svc__gamma=0.0001, score=0.7737617135207496, total= 1.0min\n",
      "[CV] svc__C=1000, svc__gamma=0.0001 ..................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svc__C=1000, svc__gamma=0.0001, score=0.789261744966443, total= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed: 104.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('bow', CountVectorizer(analyzer=<function processamento_texto at 0x7fe839f7f730>,\n",
       "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "        max_features=None, min_df=1, ngram_range=(1, 1), preproce...,\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'svc__C': [0.1, 1, 10, 1000], 'svc__gamma': [1, 0.1, 0.01, 0.001, 0.0001]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(lyric_train,label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svc__C': 1000, 'svc__gamma': 1}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_predictions = grid.predict(lyric_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.83      0.83       219\n",
      "          1       0.86      0.82      0.84       253\n",
      "          2       0.90      0.90      0.90       236\n",
      "          3       0.77      0.81      0.79       252\n",
      "\n",
      "avg / total       0.84      0.84      0.84       960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(label_test,grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svc.pkl']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(grid, \"svc.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
